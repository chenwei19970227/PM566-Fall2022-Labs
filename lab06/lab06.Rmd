---
title: "lab06-week6"
author: "chen wei"
date: "2022-09-28"
output: github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r install_libaries}
library(dplyr)
library(tidytext)
library(tidyverse)
```
## STEP 1. Read in the data
First download and then read in with data.
```{r}
if (!file.exists("mtsamples.csv")) {
  download.file("https://raw.githubusercontent.com/USCbiostats/data-science-data/master/00_mtsamples/mtsamples.csv", 
                "mtsamples.csv", method="libcurl", timeout = 60)
}

mts <- read.csv("mtsamples.csv")
str(mts)

```
```{r}
mts <- as_tibble(mts)
mts
```
##QUESTION 1:: What specialties do we have?
We can use count() from dplyr to figure out how many different catagories do we have?
```{r medical-specialty}
specialties <-
  mts %>%
  count(medical_specialty)
specialties %>%
  arrange(desc(n)) %>%
  knitr::kable()

```
there are 'r nrows(specialties)' medical specialties.
```{r barplot-of-specialty-counts}
specialties %>%
  top_n(10) %>%
  ggplot(aes(x = n, y = fct_reorder(medical_specialty,n))) + 
   geom_col()
```
The distribution is not at all uniform.
##QUESTION 2
Tokenize the the words in the transcription column
Count the number of times each token appears
Visualize the top 20 most frequent words

```{r token-transcription, cache=TRUE}
mts %>%
  unnest_tokens(word,transcription ) %>%
#anti_join(stop_words,by =c("word")) %>%
  count(word,sort=TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(word, n))) +
  geom_col()
```
there are a lot of stop words here, non-specific to medical text . We do see "patient"

##QUESTION 3
Redo visualization but remove stopwords before
Bonus points if you remove numbers as well
```{r}
mts %>%
  unnest_tokens(word, transcription) %>%
  count(word, sort = TRUE) %>%
  anti_join(stop_words, by = c("word")) %>%
  # use regular expression to filter out numbers
  filter( !grepl(pattern = "^[0-9]+$", x = word)) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(word, n))) +
  geom_col()
```
Removing the stopwords and numbers gives us a much better idea of what the text is about.
##QUESTION 4
repeat question 2, but this time tokenize into bi-grams.
```{r}
mts %>%
  unnest_ngrams(bigram, transcription, n=2) %>%
  count(bigram, sort = TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(bigram, n))) +
  geom_col()
```
```{r}
mts %>%
  unnest_ngrams(trigram, transcription, n=3) %>%
  count(trigram, sort = TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(trigram, n))) +
  geom_col()
```
Top 20 trigrams seemed to return a few more medical word group than bigrams.
##QUESTION 5
Using the results you got from questions 4. Pick a word and count the words that appears after and before it.
```{r bigrams-transcription-nextword,cache=TRUE}
ptbigram <-
  mts %>%
  unnest_ngrams(bigram, transcription, n=2) %>%
  separate(bigram,into = c("word1", "word2"), sep = " ") %>%
  select(word1, word2) %>%
  filter(word1 == "patient" | word2 == "patient")
```
Words appearing before patient:
```{r}
ptbigram %>%
  filter(word2=="patient") %>%
  count(word1, sort=TRUE) %>%
  anti_join(stop_words, by = c("word1" = "word")) %>%
  top_n(10) %>%
knitr::kable()
```
Find the words following patient:
```{r}
ptbigram %>%
  filter(word1=="patient") %>%
  count(word2, sort=TRUE) %>%
  anti_join(stop_words, by = c("word2" = "word")) %>%
  top_n(10) %>%
knitr::kable()
```
##QUESTION 6
Which words are most used in each of the specialties. you can use group_by() and top_n() from dplyr to have the calculations be done within each specialty. Remember to remove stopwords. How about the most 5 used words?
```{r top}
mts %>%
  unnest_tokens(word, transcription) %>%
  group_by(medical_specialty) %>% 
  count(word, sort = TRUE) %>%
  filter( !(word %in% stop_words$word) & !grepl(pattern = "^[0-9]+$", x = word)) %>%
  top_n(5, n) %>%
  arrange(medical_specialty, desc(n)) %>%
 knitr::kable()
```


Knit the doc and save it on GitHub.
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
